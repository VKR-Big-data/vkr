# ВКР. Исследование и сравнительный анализ средств работы с большими данными в веб-приложениях
В рамках ВКР передо мной стояла задача сравнения средств работы с большими данными. Ультимативным критерием стала временная эффективность выполнения задач(задержка для потоковой обработки и время выполнения для пакетной), однако оценивались также и другие харакетристики средств.
Изучив вопрос, было принято решение в рамках работы разделить сравниваемые средства на две категории: средства для потоковой обработки данных и средства для пакетной обработки данных - это две фундаментальные для анализа больших данных задачи, при этом практически технологически противоположные. 
## Сраниваемые технологии
В качества сравниваемых средств для потоковой обработки данных были выбраны Apache Flink и Spark Streaming. Это два мощных и популярных инструмента, обладающие различными интерфейсами для написания задач потоковой обработки данных, при этом их сравнение однозначно имеет смысл, так как они реализуют разный архитектурный подход к потоковйо обработке данных: Apache Flink обрабатывает данные истинно потоково, а Spark Streaming - микро-пакетно.
Для пакетной обработки данных были выбраны Spark, Hive on Tez и Map Reduce. Звучит не совсем корректно, поэтому нужно пояснить: Hive On Tez - стандартное для индустрии сочетание движка и интерфейса, таким образом с точки зрения временной эффектисности в оценке участвовал Tez, с точки зрения удобства интерфейса - Hive. Map Reduce задачи также писались на Hive, но в качестве движка при выполнении был именно MR.
## Вспомогательные технологии
Чтобы сравнивать средства пакетной обработки нам нужно было хранлище, в котором бы хранились данные, к которым мы бы выполняли запросы. В качестве такого хранлища был выбран стандартный компонент Apache Hadoop - HDFS. Сравниваемые фреймворки являются проектами верхнего уровня Apache(или подпроектами проектов верхнего уровня), поэтому обладают тесной интеграцией с Hadoop в целом и с HDFS в частности.
Касаемо потоковой обработки данных нам нужен был источник сообщений для Flink и Spark Streaming работ, который бы обеспечивал целостность входных данных. В качестве такого источника входных данных для работ был выбран Apache Kafka, так как он также тесно интегрирован с обоими сравниваемыми средствами потоковой обработки данных.
## Данные
Для проведение экспериментального сравнения нужен был источник данных, который подходит и для пакетной и для потоковой обработки. В качестве такого источника были выбраны чаты стриминговой платформы [Twitch](https://www.twitch.tv/). Этот исчтоник может считаться источником больших потоковых данных, как минимум количественно, так как количество приходящих по вебсокету сообщений при достаточном количестве зрителей [получается внушительным](https://stats.streamelements.com/), кроме того, можно подключаться к нескольким чатам, тем самым увеличивая скорость поступления потоковых данных в систему. Программно данные получаются с помощью IRC сокетов, для менеджемента которых в момент проведения эксперимента был создан специальный REST API сервер.
## Пайплайн
![Диаграмма потоков данных в рамках системы](https://github.com/guaNa228/vkr/blob/master/%D0%98%D0%B7%D0%BE%D0%B1%D1%80%D0%B0%D0%B6%D0%B5%D0%BD%D0%B8%D1%8F/%D0%9F%D0%BE%D1%82%D0%BE%D0%BA%20%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85.png?raw=true)
Данные поступают в систему и обрабатываются в соответствии с диаграммой, приведенной выше. Данные из чатов стримов поступают через IRC сокеты на сервер, где можно контролировать, с каких именно стримов данные будут получаться, таким образом модифицируя входную нагрузку в ходе эксперимента. Сервер же перенаправляет данные в Kafka Topic, из него данные получают задачи потоковой обработки, которые преобразуют данные. На этом же этапе производится измерение временной эффективности Spark Streaming и Flink задач(задержка), которая перенаправляется в специальные Kafka Topicи и отслеживается скриптом, который подводит результаты потокового экпсеримента, представляя эти данные. Flink и Spark Streaming работы записывают обработанные данные в HDFS хранилище. С данными из HDFS хранилища(данные представляют из себя сообщения из чатов с информацией о пользователе, отправившем сообщение и стримере, на трансляции которого это сообщение было отправлено) взаимодействуют работы пакетной обработки данных, их количеством мы также можем управлять, проводя эксперименты на разных объемах данных.
## Результаты
Так как в исследовании средства работы с большими данными поделены на две группы, результаты и выводы представим в схожем формате.
### Результаты потоковых экспериментов
| Задача        | Нагрузка(сообщ/сек) | Средняя задержка Flink(мс) | Средняя задержка Spark Streaming(мс) |
| ------------- |:-------------:| :-----:| :-----: |
| Форматирование и запись в HDFS | 31 | 3.62±1.62 | 93.83±75.97 |
| Форматирование и запись в HDFS | 77 | 4.39±2.24 | 137.10±99.41 |
| Форматирование и запись в HDFS | 123 | 4.10±2.29 | 134.21±81.62 |
| Цензурирование ненормативной лексики  | 36 | 4.24±1.55 | 209.44±156.96 |
| Цензурирование ненормативной лексики  | 80 | 6.02±3.53 | 205.11±124.51 |
| Цензурирование ненормативной лексики  | 115 | 4.63±2.23| 216.53±123.33 |

* Apache Flink демонстрирует значительно меньшую задержку при выполнении задач потоковой обработки данных, чем Spark Streaming (средняя задержка отличается в 30 раз).

* Максимальная задержка, демонстрируемая Apache Flink составляет 42мс, а Spark Streaming – 743 мс(Flink демонстрирует значительно меньшую пиковую задержку)

* Spark Streaming обладает более широким набором API для написания задач потоковой обработки данных, чем Apache Flink.

* Производительность фреймворков остается в рамках их архитектуры(микро-пакетной и истинно потоковой)

* Выбор между Apache Flink и Spark Streaming стоит делать от требований к задержке в рамках разрабатываемой системы

### Результаты пакетных экспериментов
| Название эксперимента                       | Записей в датасете | Время выполнения Spark(c) | Время выполнения Hive on Tez(c) | Время выполнения Map Reduce(c) |
|---------------------------------------------|-------------------|----------------------------|----------------------------------|---------------------------------|
| Подсчёт количества записей                  | 34650             | 49                         | 59                               | 127                             |
|                                             | 69106             | 78                         | 112                              | 224                             |
|                                             | 237531            | 232                        | 347                              | 768                             |
| Цензурирование ненормативной лексики        | 34650             | 24                         | 95                               | 224                             |
|                                             | 69106             | 58                         | 173                              | 531                             |
|                                             | 237531            | 195                        | 328                              | 1387                            |
| Топ каналов по количеству сообщений         | 34650             | 72                         | 89                               | 160                             |
|                                             | 69106             | 116                        | 139                              | 361                             |
|                                             | 237531            | 673                        | 806                              | 1514                            |
| Топ пользователей по количеству сообщений   | 34650             | 123                        | 87                               | 158                             |
|                                             | 69106             | 123                        | 144                              | 260                             |
|                                             | 237531            | 620                        | 701                              | 1415                            |

* Map Reduce нельзя считать конкурентноспособным инструментом для пакетной обработки данных.

* Hive on Tez демонстрирует отставание в скорости выполнения задач от Spark(в среднем около 25%), тем не менее, его можно считать конкурентноспособным инструментом для пакетной обработки данных, в силу удобного синтаксиса и поддержки его разработчиками.

* В классических для пакетной обработки данных задачах(группировка, упорядочивание) Hive On Tez демонстрирует гораздо меньшее отставание от Spark(около 19%), чем в задаче фильтрации нецензурной лексики из собранных сообщений(68%)

* Spark, в общем случае, является наиболее производительным из числа сравниваемых инструментов для пакетной обработки данных, к тому же обладает наиболее широким набором API(Java, Python, Scala) и поддержкой разработчиком

## Код
В репозитории также представлен код, используемый в работе, а именно:
1. `Код/Работы` - cами задачи, на которых сравнивалась временная эффективность фреймворков.
2. `Код/irc_socket_server.py` - IRC сокет сервер, манипулирующий потоком текущих данных, поступающих в систему, на основе запросов.
3. `Код/Скрипты для автоматизации тестирования работ` - Скрипты для автоматизации проведения и подведения результатов экспериментов, включая анализ информации о задержке, ее сохранение и построение графиков, а также атоматизации запуска экспериментов с заранее заданной конфигурацией.

